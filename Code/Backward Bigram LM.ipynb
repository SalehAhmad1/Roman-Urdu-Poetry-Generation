{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saleh Ahmad\n",
    "i200605@nu.edu.pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bigram_Backward_LM_Roman_Urdu():\n",
    "    def __init__(self):\n",
    "        self.ngram = 2\n",
    "\n",
    "    def fit(self,TrainCorpusVocab): #TrainCorpus = all tokens in order of occurence\n",
    "        Vocabs = defaultdict(int)\n",
    "        UniqueVocabSize = defaultdict(int)\n",
    "        VocabSize = defaultdict(int)\n",
    "        for ngram in range(self.ngram,0,-1):\n",
    "            IdxToken = 0\n",
    "            ngrams = defaultdict(int)\n",
    "            Len_Vocab = len(TrainCorpusVocab)\n",
    "            while IdxToken < Len_Vocab-ngram+1:\n",
    "                current_n_gram = TrainCorpusVocab[IdxToken]\n",
    "                for idx in range(1,ngram):\n",
    "                    current_n_gram += ' ' + TrainCorpusVocab[IdxToken+idx]\n",
    "                \n",
    "                ngrams[current_n_gram] += 1\n",
    "                IdxToken += 1\n",
    "\n",
    "            ngrams = {k:v for k,v in ngrams.items() if v > 0}\n",
    "            Vocabs[ngram] = ngrams\n",
    "            UniqueVocabSize[ngram] = len(ngrams)\n",
    "            VocabSize[ngram] = sum(ngrams.values())\n",
    "        \n",
    "        self.Vocabs = Vocabs\n",
    "        self.UniqueVocabSizes = UniqueVocabSize\n",
    "        self.VocabSizes = VocabSize\n",
    "\n",
    "    def __Get_Random_Length_Of_Verse(self):\n",
    "        #generate random length b/w 5 and 9\n",
    "        return random.randint(6,8)\n",
    "\n",
    "    def __Get_Random_Ending_Token(self,e_tokens):\n",
    "        e_tokens = np.unique(e_tokens)\n",
    "        #generate random starting token from e_tokens which is a list of ending tokens\n",
    "        return random.choice(e_tokens)\n",
    "    \n",
    "    def __Print_Vocab(self):\n",
    "        print(self.Vocabs)\n",
    "    \n",
    "\n",
    "    def __Get_Next_Word_From_Candidate(self,Sequence):\n",
    "        NGramToUse = self.ngram\n",
    "        Candidates = [ngram for ngram in self.Vocabs[NGramToUse].keys() if ''.join(ngram.split()[-1]) == Sequence]\n",
    "                \n",
    "        if len(Candidates) == 0:\n",
    "            #return any one from most used 10 words in self.Vocabs[NGramToUse-1]\n",
    "            ToReturn = random.choice(list(self.Vocabs[NGramToUse-1].keys())[:10])\n",
    "            return ToReturn\n",
    "        else:\n",
    "            Probability_Of_Candidates = np.zeros_like(Candidates)\n",
    "            for idx,candidate in enumerate(Candidates):\n",
    "                # Probability_Of_Candidates[idx] = (self.Vocabs[NGramToUse][candidate] + 1) / (self.Priors[NGramToUse-1][Sequence] + self.UniqueVocabSizes[self.ngram])\n",
    "                Probability_Of_Candidates[idx] = (self.Vocabs[NGramToUse][candidate] + 1) / (self.VocabSizes[self.ngram] + self.UniqueVocabSizes[self.ngram])\n",
    "            return Candidates[np.argmax(Probability_Of_Candidates)].split()[-2]\n",
    "\n",
    "    def predict(self,EndingTokens): #StartingTokens = list of repetitive tokens, can extract unique and count\n",
    "        '''\n",
    "        Prediction format\n",
    "        1 stanza = 14 verses (1 * 14)\n",
    "        1 verse = 6 - 8 words\n",
    "        '''        \n",
    "\n",
    "        OrderedVerse = ''\n",
    "        for idxVerse in range(0,14):\n",
    "            EndingTokenOfThisVerse = self.__Get_Random_Ending_Token(EndingTokens) #Verse ends with a random ending token, length is 1 right now\n",
    "            Verse = EndingTokenOfThisVerse\n",
    "            Sequence = EndingTokenOfThisVerse\n",
    "\n",
    "            for idxWord in range(1,self.__Get_Random_Length_Of_Verse()):\n",
    "                PrevWord = self.__Get_Next_Word_From_Candidate(Sequence)\n",
    "                Verse = PrevWord + ' ' + Verse\n",
    "                Sequence = PrevWord\n",
    "            \n",
    "            OrderedVerse += Verse + '\\n'\n",
    "            if idxVerse != 0 and idxVerse % 2 == 1:\n",
    "                OrderedVerse += '\\n'\n",
    "        return OrderedVerse \n",
    "\n",
    "    def Print_Details(self):\n",
    "        print('All ngrams',self.Vocabs.keys())\n",
    "        for ngram in self.Vocabs.keys():\n",
    "            print('ngram:',ngram)\n",
    "            print('ngrams:',list(self.Vocabs[ngram].keys())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllTokens = np.load('../Data/All_Tokens_Roman_Urdu.npy')\n",
    "AllTokens = [token.lower() for token in AllTokens]\n",
    "EndingTokens = np.load('../Data/Ending_Tokens_Roman_Urdu.npy')\n",
    "EndingTokens = [token.lower() for token in EndingTokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjLM = Bigram_Backward_LM_Roman_Urdu()\n",
    "ObjLM.fit(AllTokens)\n",
    "# ObjLM.Print_Details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dard ka jahan dil hi se darakhshan\n",
      "tha maida lazzat dard ka nuzool kitaab\n",
      "\n",
      "nah aaye nah aaye nah khmosh bathye\n",
      "hain meri na-ash ko day tilsam\n",
      "\n",
      "theen kurbateen kitni baham saghar o\n",
      "sehan gulshan mein jurrat aazma lena\n",
      "\n",
      "bacha ke ae kash فسون niaz mandi\n",
      "bacha ke gum kya be panah tera ایاغ\n",
      "\n",
      "ka jahan dil hi se aati daagh\n",
      "apna bana hai naqsh qadam mera\n",
      "\n",
      "ne apna bana hai shab hijran\n",
      "aaye nah aaye nah jayoo daman nichor\n",
      "\n",
      "lazzat dard ka jahan dil guzar\n",
      "to yeh kis ne apna bana hai فغفوری\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Pred = ObjLM.predict(EndingTokens)\n",
    "print(Pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "90857eea415e892742aa58aac1803481ac02e4a0a6170a8a09c25267b7e414aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
