{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saleh Ahmad\n",
    "i200605@nu.edu.pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laplace_LM_Roman_Urdu():\n",
    "    def __init__(self,ngram_type=None):\n",
    "        if ngram_type == None:\n",
    "            self.ngram = 2\n",
    "        else:\n",
    "            self.ngram = ngram_type\n",
    "\n",
    "    def fit(self,TrainCorpusVocab): #TrainCorpus = all tokens in order of occurence\n",
    "        Vocabs = defaultdict(int)\n",
    "        UniqueVocabSize = defaultdict(int)\n",
    "        VocabSize = defaultdict(int)\n",
    "        for ngram in range(self.ngram,0,-1):\n",
    "            IdxToken = 0\n",
    "            ngrams = defaultdict(int)\n",
    "            Len_Vocab = len(TrainCorpusVocab)\n",
    "            while IdxToken < Len_Vocab-ngram+1:\n",
    "                current_n_gram = TrainCorpusVocab[IdxToken]\n",
    "                for idx in range(1,ngram):\n",
    "                    current_n_gram += ' ' + TrainCorpusVocab[IdxToken+idx]\n",
    "                \n",
    "                ngrams[current_n_gram] += 1\n",
    "                IdxToken += 1\n",
    "\n",
    "            ngrams = {k:v for k,v in ngrams.items() if v > 0}\n",
    "            Vocabs[ngram] = ngrams\n",
    "            UniqueVocabSize[ngram] = len(ngrams)\n",
    "            VocabSize[ngram] = sum(ngrams.values())\n",
    "        \n",
    "        self.Vocabs = Vocabs\n",
    "        self.UniqueVocabSizes = UniqueVocabSize\n",
    "        self.VocabSizes = VocabSize\n",
    "\n",
    "    def __Get_Random_Length_Of_Verse(self):\n",
    "        #generate random length b/w 5 and 9\n",
    "        return random.randint(6,8)\n",
    "\n",
    "    def __Get_Random_Starting_Token(self,s_tokens):\n",
    "        #generate random starting token from s_tokens which is a list of starting tokens\n",
    "        return random.choice(s_tokens)\n",
    "    \n",
    "    def __Print_Vocab(self):\n",
    "        print(self.Vocabs)\n",
    "    \n",
    "    def __Get_Next_Word_From_Candidate(self,Sequence):\n",
    "        ngram_ToUse = len(Sequence.split()) + 1\n",
    "        Candidates = [ngram for ngram in self.Vocabs[ngram_ToUse].keys() if ' '.join(ngram.split()[0:-1]) == Sequence]\n",
    "        if len(Candidates) == 0:\n",
    "            return self.__Get_Next_Word_From_Candidate(' '.join(Sequence.split()[1:])) #BackOff\n",
    "        else:\n",
    "            Probs_Of_Candidates = np.zeros_like(Candidates)\n",
    "            for idxCandidate,candidate in enumerate(Candidates):\n",
    "                Probs_Of_Candidates[idxCandidate] = (self.Vocabs[ngram_ToUse][candidate] + 1) / (self.VocabSizes[self.ngram] + self.UniqueVocabSizes[self.ngram])\n",
    "                \n",
    "            return Candidates[np.argmax(Probs_Of_Candidates)].split()[-1] #return max prob and the next word\n",
    "\n",
    "    def __ReverseBackOff(self,sequence): \n",
    "        '''Initially the length of the sequence will be one. It will try to complete the sequence to the self.ngrams-1 length mark.\n",
    "        '''\n",
    "        for ngramIdx in range(2,self.ngram):\n",
    "            Candidates = [ngram for ngram in self.Vocabs[ngramIdx].keys() if ' '.join(ngram.split()[0:ngramIdx-1]) == sequence]\n",
    "            Probs_Of_Candidates = np.zeros_like(Candidates)\n",
    "            for idxCandidate,candidate in enumerate(Candidates):\n",
    "                Probs_Of_Candidates = (self.Vocabs[ngramIdx][candidate] + 1) / (self.VocabSizes[self.ngram] + self.UniqueVocabSizes[self.ngram])\n",
    "            Seq = sequence + ' ' + str(Candidates[np.argmax(Probs_Of_Candidates)].split()[-1])\n",
    "            sequence = Seq\n",
    "        return sequence\n",
    "\n",
    "\n",
    "    def predict(self,StartingTokens): #StartingTokens = list of repetitive tokens, can extract unique and count\n",
    "        '''\n",
    "        Prediction format\n",
    "        1 stanza = 14 verses (1 * 14)\n",
    "        1 verse = 6 - 8 words\n",
    "        '''         \n",
    "\n",
    "        Verse = ''\n",
    "        for idxVerse in range(0,14):\n",
    "            StartingTokenOfThisVerse = self.__Get_Random_Starting_Token(StartingTokens) #Verse starts with a random starting token, length is 1 right now\n",
    "            VerseLength = self.__Get_Random_Length_Of_Verse()\n",
    "            Sequence = StartingTokenOfThisVerse\n",
    "            CurrentVerse = Sequence\n",
    "\n",
    "            #Length is less than what is required by self.ngras\n",
    "            if self.ngram > 2 and len(CurrentVerse.split()) == 1:\n",
    "                NextWords = self.__ReverseBackOff(Sequence)\n",
    "                CurrentVerse = NextWords\n",
    "                Sequence = CurrentVerse\n",
    "\n",
    "            #Now the sequence is ready for self.ngram probs\n",
    "            for idxWord in range(len(CurrentVerse.split()),VerseLength):\n",
    "                NextWords = self.__Get_Next_Word_From_Candidate(Sequence)\n",
    "                Sequence = ' '.join(Sequence.split()[1:] + ([NextWords]))\n",
    "                CurrentVerse += ' ' + NextWords\n",
    "                \n",
    "            CurrentVerse += '\\n'\n",
    "            if idxVerse != 0 and idxVerse % 2 == 1:\n",
    "                CurrentVerse += '\\n'\n",
    "            Verse += CurrentVerse\n",
    "        return Verse \n",
    "\n",
    "    def Print_Details(self):\n",
    "        print('All ngrams',self.Vocabs.keys())\n",
    "        for ngram in self.Vocabs.keys():\n",
    "            print('ngram:',ngram)\n",
    "            print('ngrams:',list(self.Vocabs[ngram].keys())[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjLM = Laplace_LM_Roman_Urdu(3)\n",
    "\n",
    "AllTokens = np.load('../Data/All_Tokens_Roman_Urdu.npy')\n",
    "AllTokens = [token.lower() for token in AllTokens]\n",
    "StartingTokens = np.load('../Data/Starting_Tokens_Roman_Urdu.npy')\n",
    "StartingTokens = [token.lower() for token in StartingTokens]\n",
    "ObjLM.fit(AllTokens)\n",
    "\n",
    "# ObjLM.Print_Details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = ObjLM.predict(StartingTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baghal mein ghair ki aaj aap sotay hain\n",
      "taat o zuhad par tabiyat idhar\n",
      "\n",
      "arsa جولاں tha sun-hwa wamandgy se\n",
      "ik umar se aaya nah gaya aakhir\n",
      "\n",
      "yaan yeh hijaab paas waza raah mein\n",
      "ya koi gul khula asshk amde ke\n",
      "\n",
      "zindagi mein maza nahi baqi zabt ka hosla\n",
      "kya aakhir shab dil mein phir گریے ne\n",
      "\n",
      "teri mohar o wafa ke baab aaye kar\n",
      "hai yaaro saba se kuch to\n",
      "\n",
      "niklana khuld se aadam ka suntay aaye\n",
      "kon karta hai wafa ehad wafa aakhir shab\n",
      "\n",
      "daam har mouj mein hai ke yeh\n",
      "haazir ki kaayenaat hai kya jo kis\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "90857eea415e892742aa58aac1803481ac02e4a0a6170a8a09c25267b7e414aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
